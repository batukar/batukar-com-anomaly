{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vh1kzOl97Bbm"
   },
   "source": [
    "Adım 1: Veriyi Okuma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pQJlk4hf7GC7"
   },
   "source": [
    "**Adım 3: Yeni Veriyi Dosyaya Kaydetme**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4NcpCGoT7lxn"
   },
   "source": [
    "**Adım 4: Yeni Veriyi Kontrol Edin**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KCNBNX2m7u0n"
   },
   "source": [
    "**Adım 5: Artırılmış Veri ile Model Eğitimi**\n",
    "\n",
    "Adım 5.1: Yeni Veriyi Eğitim ve Test Setlerine Bölme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kb-yJByi75rp"
   },
   "source": [
    "Adım 5.2: Veriyi Tokenize Etme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iaK4Z6HT79Zo"
   },
   "source": [
    "Adım 5.3: Tensor Formatına Dönüştürme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i025WcwH8Btt"
   },
   "source": [
    "Adım 5.4: Model Eğitimi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p34M_10J8HEB"
   },
   "source": [
    "Adım 5.5: Performans Değerlendirmesi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z_5Qp6l58PGN"
   },
   "source": [
    "**Adım 6: Model Performansının Detaylı Değerlendirilmesi**\n",
    "\n",
    "Adım 6.1: Karmaşıklık Matrisi ve Sınıflandırma Raporu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MHjKh3fN8aDN"
   },
   "source": [
    "Adım 6.2: Karmaşıklık Matrisi Görselleştirme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K8eo-f5Y8eBr"
   },
   "source": [
    "Adım 6.3: Precision, Recall ve F1-Score Görselleştirme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LfKIY6C18ii2"
   },
   "source": [
    "Adım 6.4: Tahmin Sonuçlarının Örnek Analizi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s9qAevGN8yUK"
   },
   "source": [
    "**Adım 7: Modelin Gerçek Hayatta Kullanımı**\n",
    "\n",
    "Adım 7.1: Gerçek Log Verileri ile Tahmin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T_eRumOz853x"
   },
   "source": [
    "Adım 7.2: Tahmin Sonuçlarının Analizi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tHXd7pa68-bV"
   },
   "source": [
    "Adım 7.3: Tahmin Dağılımının Görselleştirilmesi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yNbbXSpV9Bqc"
   },
   "source": [
    "Adım 7.4: Yeni Veriler için Anomali Tespiti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w1meXvlg9IDR"
   },
   "source": [
    "Adım 7: Model Performansının Sonuçlarını Analiz Etme\n",
    "\n",
    "Adım 7.1: Model Performansının Yorumlanması"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8825b989",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Log dosyasını yükleme ve ayrıştırma\n",
    "def parse_log(log):\n",
    "    log_pattern = r'(?P<ip>\\d+\\.\\d+\\.\\d+\\.\\d+) - - \\[(?P<timestamp>.*?)\\] \"(?P<method>.*?) (?P<url>.*?) (?P<protocol>.*?)\" (?P<status>\\d+) (?P<size>\\d+|-)'\n",
    "    match = re.match(log_pattern, log)\n",
    "    return match.groupdict() if match else None\n",
    "\n",
    "# Log dosyasını liste olarak yükleme\n",
    "logs = []  # Log dosyanız burada listelenmeli\n",
    "\n",
    "# Logları DataFrame'e dönüştürme\n",
    "parsed_logs = [parse_log(log) for log in logs if parse_log(log)]\n",
    "logs_df = pd.DataFrame(parsed_logs)\n",
    "\n",
    "# Etiketleri ekleme\n",
    "logs_df['label'] = logs_df['status'].apply(lambda x: 1 if x.startswith('4') or x.startswith('5') else 0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bf01a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "\n",
    "# Sentetik veri üretim fonksiyonu\n",
    "def generate_synthetic_data(df, target_size=10000):\n",
    "    # Zaman damgasını datetime formatına dönüştürme\n",
    "    if 'timestamp' in df.columns:\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')\n",
    "        df = df.dropna(subset=['timestamp'])\n",
    "\n",
    "    synthetic_data = df.copy()\n",
    "    rows = []\n",
    "\n",
    "    # Sentetik veri üretimi\n",
    "    while len(synthetic_data) + len(rows) < target_size:\n",
    "        for _, row in df.iterrows():\n",
    "            manipulated_row = row.copy()\n",
    "            manipulated_row['ip'] = f\"{random.randint(1, 255)}.{random.randint(1, 255)}.{random.randint(1, 255)}.{random.randint(1, 255)}\"\n",
    "            manipulated_row['timestamp'] = manipulated_row['timestamp'] + pd.Timedelta(seconds=random.randint(1, 3600))\n",
    "            manipulated_row['method'] = random.choice([\"GET\", \"POST\", \"HEAD\", \"OPTIONS\", \"DELETE\"])\n",
    "            manipulated_row['status'] = random.choice([\"200\", \"404\", \"500\", \"403\", \"302\"])\n",
    "            manipulated_row['url'] = manipulated_row['url'] + f\"?query={random.randint(1, 100)}\"\n",
    "            rows.append(manipulated_row)\n",
    "\n",
    "            if len(synthetic_data) + len(rows) >= target_size:\n",
    "                break\n",
    "\n",
    "    # Performans için tüm satırları birleştir\n",
    "    synthetic_data = pd.concat([synthetic_data, pd.DataFrame(rows)], ignore_index=True)\n",
    "\n",
    "    print(f\"Sentetik veri üretildi: {len(synthetic_data)} kayıt.\")\n",
    "    return synthetic_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4537f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Sınıf dengesini sağlama fonksiyonu\n",
    "def balance_classes_with_smote(df):\n",
    "    if 'url' not in df.columns or 'label' not in df.columns:\n",
    "        raise ValueError(\"DataFrame'de 'url' veya 'label' sütunu eksik!\")\n",
    "\n",
    "    # TF-IDF ile sayısallaştırma\n",
    "    vectorizer = TfidfVectorizer(max_features=1000)\n",
    "    X_numeric = vectorizer.fit_transform(df['url']).toarray()\n",
    "    y = df['label']\n",
    "\n",
    "    # SMOTE ile dengeleme\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_balanced, y_balanced = smote.fit_resample(X_numeric, y)\n",
    "\n",
    "    print(f\"Sınıf dengesi sağlandı: {len(X_balanced)} kayıt.\")\n",
    "    return X_balanced, y_balanced\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfcd784",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Tüm süreci birleştirme\n",
    "def process_data(df, target_size=10000):\n",
    "    # Sentetik veri üretimi\n",
    "    synthetic_data = generate_synthetic_data(df, target_size)\n",
    "\n",
    "    # Sınıf dengesini sağlama\n",
    "    X_balanced, y_balanced = balance_classes_with_smote(synthetic_data)\n",
    "\n",
    "    return X_balanced, y_balanced\n",
    "\n",
    "# Kullanım\n",
    "X_balanced, y_balanced = process_data(logs_df, target_size=10000)\n",
    "print(f\"Sonuç: Dengeli veri boyutu: {len(X_balanced)}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
